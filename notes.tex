\documentclass[12pt, letterpaper, twoside]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[T1,T2A]{fontenc}
\usepackage[english,russian]{babel}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

\usepackage{color} %% это для отображения цвета в коде
\usepackage{listings} %% собственно, это и есть пакет listings

\usepackage{hyperref}

\usepackage{caption}
\DeclareCaptionFont{white}{\color{white}} %% это сделает текст заголовка белым
%% код ниже нарисует серую рамочку вокруг заголовка кода.
\DeclareCaptionFormat{listing}{\colorbox{gray}{\parbox{\textwidth}{#1#2#3}}}
\captionsetup[lstlisting]{format=listing,labelfont=white,textfont=white}

\graphicspath{ {images/} }
\title{Python profiler}
\author{Oleg Shipulin} 
\date{\today}

\begin{document}

\maketitle

\thispagestyle{empty} % Убираем нумерацию на титуле
\newpage % Разрыв страницы после титула

\tableofcontents % Добавляем оглавление
\newpage

\lstset{
	breaklines=true,
	captionpos=t,
	tabsize=2,
	numbersep=5pt,
	numberstyle=\tiny,
	basicstyle=\small\sffamily,
	numbers=left,
	stepnumber=1,
	showtabs=false,
	frame=single,
}

\section{Введение}
\subsection{Мотивация}
Так как Python сам по себе не самый быстрый язык программирования, то по мере
роста проекта, усложнения его архитектуры и увеличения объемов обрабатывамых данных, даже
незначительные куски неэффективного кода могут накапливать задержки, превращая программу в
невероятно медленную. Пример такого кода - применение не самой оптимизированный структуры
данных для конкретного сценария.

Найти bottleneck (узкое горлышко) и не самого оптимизированного кода помогает профилирование,
о котором и пойдёт речь в последующей статье.

\subsection{Объект и предмет исследования}

\hspace{0.44cm}\textbf{Объектом} исследования являются программные средства динамического анализа
производительности кода на языке Python, включая как встроенные и сторонние
профилировщики, так и системные утилиты, позволяющие исследовать выполнение
Python-программ на различных уровнях абстракции: от интерпретируемого кода
до нативных расширений и системных вызовов.

\textbf{Предметом} исследования выступают методы и техники профилирования,
реализованные в этих средствах: инструментирование (tracing),
статистическое профилирование (sampling), построчный анализ,
профилирование памяти, а также подходы к анализу производительности
на уровне операционной системы (perf, Valgrind) и их применимость
к Python-приложениям.

\subsection{Цель исследования}

\hspace{0.44cm}\textbf{Цель} работы — провести комплексный сравнительный анализ
инструментов профилирования Python, охватывающий все уровни исполнения
программы: от исходного кода на Python до нативных расширений и
взаимодействия с ядром ОС. На основе этого анализа выявить сильные
и слабые стороны каждого класса инструментов, определить
области их эффективного применения и предложить рекомендации по
выбору средств для решения конкретных задач оптимизации производительности.


Для достижения поставленной цели необходимо решить следующие \textbf{задачи}:
\begin{enumerate}
	\item Рассмотреть теоретические основы профилирования: определить понятие
	      профилирования, классифицировать существующие методы (инструментирование
	      и статистическое профилирование), описать их достоинства и недостатки.
	\item Выполнить обзор профилировщиков, входящих в стандартную
	      библиотеку Python (profile, cProfile), и охарактеризовать особенности
	      их реализации, достоинства и ограничения.
	\item Изучить специализированные профилировщики, ориентированные на
	      построчный анализ (line\_profiler), анализ памяти (memory\_profiler),
	      работу с многопоточными и асинхронными приложениями (yappi).
	\item Рассмотреть инструменты статистического профилирования
	      (py-spy, pprofile), позволяющие выполнять анализ без остановки
	      программы и с минимальным вмешательством в её работу.
	\item Проанализировать возможности профилирования нативных
	      расширений Python (C extensions) с использованием
	      инструментов для отладки и профилирования на уровне
	      языков C/C++ (gprof, Valgrind, perf) и их интеграцию с Python-процессами.
	\item Исследовать системные профилировщики (perf, SystemTap,
	      DTrace) и методы их применения для анализа
	      Python-приложений, включая получение смешанных стеков вызовов (Python + C).
	\item Сравнить перечисленные средства по ключевым критериям:
	      скорость работы, точность измерений, область применения,
	      накладываемые ограничения и требования к окружению.
	\item На основе проведённого анализа сформулировать практические
	      рекомендации по выбору инструментов профилирования для различных
	      сценариев разработки и эксплуатации Python-программ.
\end{enumerate}

\newpage{}
\section{Анализ и визуализация результатов профилирования}
После сбора данных профилирования перед разработчиком встаёт задача интерпретации полученных метрик. Разные профилировщики используют различные форматы вывода, однако существуют универсальные инструменты, позволяющие анализировать и визуализировать статистику вне зависимости от того, каким именно профилировщиком она была собрана. В этой главе рассматриваются основные форматы хранения профилей, способы их обработки с помощью стандартного модуля \texttt{pstats}, а также популярные инструменты визуализации: \texttt{snakeviz}, \texttt{gprof2dot} и \texttt{KCachegrind}.

\subsection{Форматы вывода профилировщиков}
Профилировщики Python могут сохранять результаты в нескольких форматах:
\begin{itemize}
	\item \textbf{Текстовый} — простой для чтения человеком, но неудобный для автоматической обработки. Используется при вызове \texttt{print\_stats()} модуля \texttt{pstats} или при запуске профилировщика без указания выходного файла.
	\item \textbf{Бинарный формат \texttt{pstats}} — внутренний формат модуля \texttt{pstats}, используемый \texttt{profile} и \texttt{cProfile} по умолчанию. Файлы обычно имеют расширение \texttt{.prof} или \texttt{.pstats}.
	\item \textbf{Callgrind-совместимый формат} — формат, используемый инструментом \texttt{callgrind} из состава Valgrind. Поддерживается профилировщиком \texttt{pprofile} и может быть создан из \texttt{pstats} с помощью утилиты \texttt{pyprof2calltree}.
	\item \textbf{JSON и другие} — некоторые современные инструменты, такие как \texttt{py-spy}, могут экспортировать данные в JSON для последующей обработки.
\end{itemize}
В данной главе основное внимание уделяется работе с форматом \texttt{pstats}, как наиболее распространённому среди встроенных средств Python.

\subsection{Модуль pstats: базовый анализ в консоли}
Модуль \texttt{pstats} входит в стандартную библиотеку Python и предоставляет набор инструментов для сортировки, фильтрации и вывода статистики, собранной профилировщиками \texttt{profile} и \texttt{cProfile}. Работа с ним может осуществляться как в интерактивном режиме, так и скриптово.

\subsubsection*{Загрузка статистики}
Для начала работы необходимо создать объект \texttt{Stats}, передав ему имя файла с профилем:
\begin{lstlisting}
import pstats
stats = pstats.Stats('output.prof')
\end{lstlisting}
Можно загрузить несколько файлов сразу, перечислив их в конструкторе.

\subsubsection*{Очистка путей}
Часто полные абсолютные пути к файлам загромождают вывод. Метод \texttt{strip\_dirs()} удаляет пути к каталогам, оставляя только имена файлов:
\begin{lstlisting}
stats.strip_dirs()
\end{lstlisting}

\subsubsection*{Сортировка}
Перед выводом статистику необходимо отсортировать по одному из ключей. Наиболее употребимые:
\begin{itemize}
	\item \texttt{'cumtime'} — суммарное время функции с учётом дочерних вызовов;
	\item \texttt{'tottime'} — собственное время функции (без учёта вызовов);
	\item \texttt{'ncalls'} — количество вызовов;
	\item \texttt{'pcalls'} — количество примитивных вызовов.
\end{itemize}
Пример сортировки по собственному времени:
\begin{lstlisting}
stats.sort_stats('tottime')
\end{lstlisting}

\subsubsection*{Вывод}
Метод \texttt{print\_stats(n)} выводит первые \texttt{n} записей:
\begin{lstlisting}
stats.print_stats(10)
\end{lstlisting}
Каждая строка вывода содержит:
\begin{itemize}
	\item \texttt{ncalls} — общее число вызовов (в скобках может указываться число рекурсивных вызовов);
	\item \texttt{tottime} — суммарное время, проведённое непосредственно в теле функции (без вызовов);
	\item \texttt{percall} — \texttt{tottime}, делённое на \texttt{ncalls};
	\item \texttt{cumtime} — суммарное время, проведённое в функции и во всех вызванных ею функциях;
	\item \texttt{percall} — \texttt{cumtime}, делённое на количество примитивных вызовов;
	\item \texttt{filename:lineno(function)} — имя файла, номер строки и имя функции.
\end{itemize}

\subsubsection*{Просмотр вызывающих и вызываемых функций}
Методы \texttt{print\_callers()} и \texttt{print\_callees()} показывают, какие функции вызывают данную и какие вызывает она сама. Это помогает понять структуру взаимодействия:
\begin{lstlisting}
stats.print_callers(5)
stats.print_callees(5)
\end{lstlisting}

\subsubsection*{Фильтрация}
Модуль \texttt{pstats} позволяет фильтровать вывод по имени файла или функции с помощью метода \texttt{print\_stats()} с регулярными выражениями. Например, чтобы оставить только функции из файла \texttt{mycode.py}:
\begin{lstlisting}
stats.print_stats('mycode.py')
\end{lstlisting}

\subsection{Интерактивная визуализация с SnakeViz}
\textbf{SnakeViz} — это браузерный инструмент для интерактивного исследования профилей \texttt{cProfile}. Он предоставляет два основных вида визуализации: «солнечные лучи» (sunburst) и иерархический список (icicle).

\subsubsection*{Установка}
\begin{lstlisting}[language=bash]
pip install snakeviz
\end{lstlisting}

\subsubsection*{Запуск}
Для просмотра профиля достаточно выполнить:
\begin{lstlisting}[language=bash]
snakeviz output.prof
\end{lstlisting}
После этого откроется окно браузера с интерактивной диаграммой.

\subsubsection*{Интерфейс и навигация в SnakeViz}
После запуска команды \texttt{snakeviz output.prof} в браузере открывается страница с интерактивной визуализацией. По умолчанию отображается диаграмма в стиле «солнечные лучи» (sunburst). В левом верхнем углу расположена панель управления, позволяющая:

\begin{itemize}
	\item \textbf{Переключаться между режимами отображения}: sunburst (рис. \ref{snakeviz_sunburst}) и icicle (рис. \ref{snakevize_icicle}). Режим icicle представляет иерархию в виде горизонтальных полос, где каждая полоса соответствует уровню вызовов, а ширина полосы пропорциональна времени.
	\item \textbf{Фильтровать по имени функции или модуля}: в поле поиска можно ввести регулярное выражение, чтобы оставить только те функции, которые соответствуют шаблону. Это особенно полезно для выделения кода конкретного модуля.
	\item \textbf{Настраивать цветовую схему}: по умолчанию цвета назначаются случайным образом, но можно включить окраску по модулям, что упрощает идентификацию различных частей программы.
	\item \textbf{Сортировать} дочерние функции по времени или имени.
	\item \textbf{Экспортировать текущий вид} как изображение (PNG) через стандартные средства браузера (правый клик → «Сохранить картинку как…»).
\end{itemize}

\subsubsection*{Интерпретация sunburst-диаграммы}
На рис. \ref{snakeviz_sunburst} представлен пример sunburst-диаграммы. Центральный круг — корневая функция (обычно \texttt{<module>}). Каждое следующее кольцо соответствует уровню вложенности вызовов. Сегменты внутри кольца представляют функции, вызванные на этом уровне. Угловой размер сегмента пропорционален суммарному времени, проведённому в данной функции и всех её потомках (cumulative time). Таким образом, крупные сегменты сразу указывают на горячие участки.

\begin{figure}[hbtp]
	\centering
	\includegraphics[width=1\textwidth]{snakeviz_sunburst.png}
	\caption{Sunburst-диаграмма в SnakeViz}
	\label{snakeviz_sunburst}
\end{figure}

При наведении курсора на любой сегмент всплывает подсказка с подробной информацией:
\begin{itemize}
	\item имя функции и модуль;
	\item собственное время (tottime) — время, потраченное непосредственно внутри функции (в секундах и процентах);
	\item суммарное время (cumtime) — включая все вызовы;
	\item количество вызовов (ncalls).
\end{itemize}
Цветовая дифференциация помогает различать разные модули или файлы, если включена соответствующая опция.

\subsubsection*{Интерпретация icicle-диаграммы}
Режим icicle (рис. \ref{snakevize_icicle}) представляет иерархию в виде
горизонтальных линий. Верхний уровень — корневая функция, под ним располагаются вызванные функции и т.д. Длина каждой полосы пропорциональна суммарному времени. Этот вид удобен для сравнения долей времени на одном уровне иерархии, а также для отслеживания цепочек вызовов без радиальных искажений.

\begin{figure}[hbtp]
	\centering
	\includegraphics[width=1\textwidth]{snakevize_icicle.png}
	\caption{Icicle-диаграмма в SnakeViz}
	\label{snakevize_icicle}
\end{figure}

\subsubsection*{Что можно понять с помощью SnakeViz}
SnakeViz позволяет быстро ответить на ключевые вопросы оптимизации:
\begin{itemize}
	\item \textbf{Какие функции потребляют больше всего времени?} — крупные сегменты в центре или длинные полосы сразу бросаются в глаза.
	\item \textbf{Как распределяется время внутри функции?} — можно увидеть, сколько времени уходит на дочерние вызовы, а сколько — на собственный код.
	\item \textbf{Есть ли рекурсивные или циклические вызовы?} — они проявляются как повторяющиеся сегменты на разных уровнях.
	\item \textbf{Какие модули вносят основной вклад?} — при окраске по модулям легко выделить проблемные библиотеки.
	\item \textbf{Насколько оправданы вызовы вспомогательных функций?} — если мелкая функция вызывается огромное число раз и занимает значительное время, это повод задуматься об оптимизации или кешировании.
\end{itemize}
SnakeViz не даёт абсолютно точных цифр (для этого лучше использовать \texttt{pstats}), но предоставляет интуитивно понятную картину, с которой удобно начинать анализ. Выявив крупные сегменты, разработчик может затем детально исследовать соответствующие функции с помощью \texttt{line\_profiler} или других средств.

\subsubsection*{Дополнительные возможности}
SnakeViz поддерживает загрузку нескольких профилей одновременно (например, для сравнения до и после оптимизации), а также позволяет сохранять текущее состояние фильтров в URL для передачи коллегам. Документация по проекту доступна на официальном сайте \url{https://jiffyclub.github.io/snakeviz/}.


\subsection{Графы вызовов с gprof2dot и Graphviz}
Утилита \texttt{gprof2dot} преобразует профили множества форматов (включая \texttt{pstats}) в граф в формате DOT, который затем визуализируется программой \texttt{dot} из пакета Graphviz.

\subsubsection*{Установка}
\begin{lstlisting}[language=bash]
pip install gprof2dot
\end{lstlisting}
Для работы также необходимо установить Graphviz (доступен через системные менеджеры пакетов: \texttt{apt install graphviz}, \texttt{brew install graphviz} и т.д.).

\subsubsection*{Построение графа}
Базовая команда для создания PNG-изображения:
\begin{lstlisting}[language=bash]
python -m gprof2dot -f pstats output.prof | dot -Tpng -o callgraph.png
\end{lstlisting}

\begin{figure}[hbtp]
	\centering
	\includegraphics[width=1\textwidth]{callgraph.png}
	\caption{callgraph}
	\label{callgraph}
\end{figure}


Ключ \texttt{-f pstats} указывает формат входных данных. Дополнительные опции \texttt{gprof2dot} позволяют настраивать отображение:
\begin{itemize}
	\item \texttt{--node-thres 0.5} — не показывать узлы, занимающие менее 0.5\% времени;
	\item \texttt{--edge-thres 0.1} — не показывать рёбра, по которым передаётся менее 0.1\% времени;
	\item \texttt{--color-nodes-by-self} — окрашивать узлы по собственному времени (по умолчанию — по суммарному).
\end{itemize}
Полученный граф наглядно демонстрирует «горячие» функции и пути вызовов.

\subsubsection*{Анализ графа вызовов}
На рис. \ref{callgraph} представлен типичный граф вызовов, построенный утилитой \texttt{gprof2dot} по данным профилирования. Граф состоит из узлов (прямоугольников), соответствующих функциям, и направленных рёбер, показывающих, какая функция какую вызывает. Каждый узел содержит следующую информацию:
\begin{itemize}
	\item имя функции и модуль (например, \texttt{main:16.fib\_recursive});
	\item общее время, проведённое в функции и её потомках, в процентах от общего времени выполнения программы (верхнее число в узле);
	\item собственное время функции (без учёта дочерних вызовов) в процентах (число в скобках);
	\item количество вызовов данной функции (например, \texttt{29860703x}).
\end{itemize}
Рёбра подписаны процентами, показывающими, какая доля времени вызывающей функции была передана вызываемой (или сколько времени заняли вызовы).

В приведённом примере можно сделать следующие наблюдения:
\begin{itemize}
	\item Основным потребителем времени является рекурсивная функция \texttt{fib\_recursive}, на которую приходится 85.98\% общего времени и столько же собственного (85.98\%). Это говорит о том, что почти всё время программа проводит непосредственно в этой функции, а не во вспомогательных вызовах. Количество вызовов (почти 30 миллионов) объясняет такое поведение: функция чрезвычайно неэффективна из-за экспоненциального роста числа рекурсивных вызовов.
	\item Функция \texttt{simulate\_io} занимает 10.53\% общего времени, но её собственное время близко к нулю (0.00\%), поскольку почти всё время уходит на вызов встроенной функции \texttt{time.sleep}. Это видно по ребру с надписью 10.53\%, ведущему к узлу \texttt{<built-in method time.sleep>}, который имеет 10.53\% собственного времени. Таким образом, здесь мы имеем дело не с вычислительной нагрузкой, а с ожиданием ввода-вывода.
	\item Функции генерации случайных чисел (\texttt{randint},
	      \texttt{randrange}, \texttt{\_randbelow\_with\_getrandbits}) в сумме
	      занимают около 2–3\% времени и вызываются 100+000 раз, что соответствует ожидаемому поведению.
	\item Корневая функция \texttt{<module>} и \texttt{main} имеют общее время 100\% и 99.95\% соответственно, что естественно, так как они являются точками входа.
\end{itemize}

Граф вызовов позволяет быстро идентифицировать горячие пути в программе. Красные/оранжевые узлы обычно соответствуют функциям с наибольшей долей времени (в зависимости от цветовой схемы). Анализируя структуру графа, можно:
\begin{itemize}
	\item Найти функции, которые вызываются аномально часто (как \texttt{fib\_recursive}) — это сигнал к оптимизации алгоритма или введению кеширования.
	\item Отличить вычислительные узкие места от операций ввода-вывода (как \texttt{simulate\_io}): если собственное время функции мало, а общее велико за счёт вызовов системных или библиотечных функций, проблема может быть в излишних ожиданиях или неэффективных внешних вызовах.
	\item Проследить цепочки вызовов, ведущие к наиболее затратным функциям, чтобы понять контекст их использования.
	\item Оценить, насколько равномерно распределено время между различными модулями.
\end{itemize}
Таким образом, граф вызовов служит мощным инструментом первичной диагностики, позволяя с одного взгляда определить, куда направить дальнейшие усилия по оптимизации.

\subsection{Профессиональные инструменты: KCachegrind / QCachegrind}
\textbf{KCachegrind} (и его аналог для macOS/Windows \textbf{QCachegrind}) — мощный визуализатор профилей, изначально созданный для работы с данными Valgrind. Он поддерживает иерархическое отображение времени, графы вызовов, аннотированный исходный код и множество статистических сводок.

\subsubsection*{Конвертация профиля в формат callgrind}
Для использования \texttt{pstats}-файла в KCachegrind необходимо преобразовать его с помощью утилиты \texttt{pyprof2calltree}:
\begin{lstlisting}[language=bash]
pip install pyprof2calltree
pyprof2calltree -i output.prof -o callgrind.out
\end{lstlisting}
Затем полученный файл открывается в KCachegrind:
\begin{lstlisting}[language=bash]
kcachegrind callgrind.out
\end{lstlisting}

\begin{figure}[hbtp]
	\centering
	\includegraphics[width=1\textwidth]{KCachegrind.png}
	\caption{KCachegrind}
	\label{KCachegrind}
\end{figure}


\subsubsection*{Возможности KCachegrind}
Программа предоставляет:
\begin{itemize}
	\item Древовидную карту вызовов (Call Graph) с цветовой индикацией времени;
	\item Таблицы функций с сортировкой по разным метрикам;
	\item Просмотр исходного кода с аннотацией времени по строкам;
	\item Статистику по вызывающим/вызываемым функциям;
	\item Экспорт в различные форматы.
\end{itemize}
KCachegrind особенно полезен при глубоком анализе больших проектов, где требуется одновременное изучение множества взаимосвязей.

\subsection{Сравнение инструментов визуализации}
Выбор инструмента зависит от конкретной задачи:
\begin{itemize}
	\item \textbf{pstats} — незаменим для быстрого консольного анализа, автоматизации в скриптах и интеграции в тесты.
	\item \textbf{SnakeViz} — идеален для интерактивного исследования: позволяет «пройти» по иерархии вызовов, быстро выявить основные потребители времени.
	\item \textbf{gprof2dot} — лучший выбор для создания статичных графов, которые можно встраивать в отчёты или презентации.
	\item \textbf{KCachegrind} — профессиональный инструмент для всестороннего анализа, особенно когда требуется сопоставление с исходным кодом и работа с большими объёмами данных.
\end{itemize}
Комбинируя эти инструменты, разработчик может эффективно исследовать производительность программы на любом уровне детализации.

\newpage
\section{Профилирование}
\subsection{Виды профилирования}
\textbf{Профилирование}. Определение профилирования везде разное, но в общем
смысле \textit{профилирование} - процесс динамического анализа работы кода, направленный
на сбор метрик её выполнения. К этим метрикам можно отнести:

\begin{itemize}
	\item Время выполнения функций, методов, строк;
	\item Использование оперативной памяти, а именно выделение, освобождение, утечки;
	\item Частота и количество вызовов функций;
	\item Загрузка cpu;
	\item Сколько занимает ввод-вывод.
\end{itemize}
Полученные данные позволяют выявить узкие места
(\textit{bottlenecks}) и обоснованно провести оптимизацию.


\subsection{Основные методы профилирования}
По способу сбора информации профилировщики делятся на два принципиально разных класса:

\begin{enumerate}
	\item \textbf{Инструментирование} (\textit{tracing} или \textit{instrumentation}).
	\item \textbf{Статистическое профилирование} (\textit{sampling}).
\end{enumerate}

\subsection{Инструментирование (tracing)}
Инструментирование — метод динамического анализа,
при котором в исходный или бинарный код программы автоматически
встраиваются специальные счетчики (зонды) для точного измерения
производительности: времени выполнения функций, количества вызовов и потребления памяти.\\

Достоинства:
\begin{itemize}
	\item Высокая точность — фиксируется каждый вызов и точное время его выполнения
	\item Собирается исчерпывающая статистика (количество вызовов, длительность, иерархия).
\end{itemize}

Недостатки:
\begin{itemize}
	\item Значительное замедление работы программы
	      (от 2–3 до 10–100 раз в зависимости от языка и реализации)
	\item Сам факт внедрения зондов может искажать реальную производительность, особенно для короткоживущих функций
\end{itemize}

\subsection{Статистическое (sampling)}
\textbf{Статистическое профилирование} - метод анализа производительности ПО,
при котором профилировщик через заданные интервалы времени делает снимки
состояния программы, определяя выполняемые функции, что позволяет с минимальным
влиянием на скорость выявить узкие места. На основе этих снимков строится вероятностная
картина распределения времени.\\
\textit{Пример} - программа прерывается по таймеру, после чего записываются текущий адрес
инструкции или стек вызовов.

Вкратцe: при периодическом снимке экрана нет точной, как при tracing, но зато
почти не замедляется прогон программы. На особо мелких функциях может очень плохо отрабатывать. \\

Достоинства:
\begin{itemize}
	\item Минимальное влияние на скорость работы программы
	\item Возможность профилировать уже запущенные процессы без
	      их остановки и без доступа к исходному коду.
\end{itemize}

Недостатки:
\begin{itemize}
	\item Меньшая точность - кратковременные функции могут быть грубо говоря не замечены.
	\item Результаты носят статистический характер и требуют репрезентативной выборки.
\end{itemize}

\subsection{Сравнение методов}
Выбор между инструментированием и статистическим профилированием зависит от конкретной задачи:
\begin{itemize}
	\item Если требуется абсолютно точная информация о каждом вызове, то предпочтительно инструментирование.
	\item Если приложение работает в промышленной среде, замедление недопустимо, или нужно диагностировать
	      проблему на лету, то применяют статистический подход.
\end{itemize}

В следующих разделах будут рассмотрены конкретные реализации этих методов в экосистеме Python, их особенности и примеры использования.

\newpage
\section{Профилирование на уровне интерпретатора Python}

\subsection{Инструментирующие профилировщики}

Экосистема Python предлагает широкий выбор профилировщиков
как в стандартной библиотеке, так и в сторонних пакетах. Среди них:

\begin{itemize}
	\item profile (стандартная библиотека, Legacy)
	\item cProfile (стандартная библиотека)
	\item line\_profiler (построчное профилирование)
	\item memory\_profiler (профилирование памяти)
	\item yappi (многопоточное и асинхронное профилирование)
\end{itemize}


\subsubsection{Profile (Legacy)}
\textbf{\textit{Profile}} - Python-профилировщик, входящий в стандартную библиотеку.
Он реализует метод инструментирования (\textit{tracing}) и собирает детальную статистику
о вызовах функций, времени их выполнения и количестве обращений.

\subsubsection*{Реализация}

\textbf{\textit{profile}} написан целиком на Python (pure Python). Это обеспечивает его
переносимость, но приводит к значительным накладным расходов. Из-за своей реализации он считается
\textbf{устаревшим}, так как в стандартную библиотеку добавил cProfile, который написан на
C extensions (то есть на языке Си, который дергается из кода Python).

\subsubsection*{Принцип работы}
Профилировщик перехватывает события вызова и возврата из каждой функции с помощью
механизма \texttt{sys.setprofile()}. На каждый вызов засекается время, ведётся
подсчёт количества обращений и строится иерархия вызовов.

\begin{lstlisting}[label=profile]
import profile

def heavy_func():
	total = 0
	for i in range(1000):
	total += i ** 2
	return total

profile.run('heavy_func()', 'profile_stats.prof')
profile.runctx('heavy_func()', globals(), locals(), 'profile_ctx.prof')
\end{lstlisting}

\textbf{Анализ:}\\
Для анализа сохранённой статистики используется модуль \textbf{\textit{pstats}}
\newline

\begin{lstlisting}[label=pstats_profile]
import pstats
stats = pstats.Stats('profile_stats.prof')
stats.sort_stats('cumtime').print_stats(10)
\end{lstlisting}

\subsubsection*{Недостатки profile}
\begin{enumerate}
	\item Так как реализация написана на Python, то средство
	      крайне медленное по сравнению с cProfile и может замедлять прогон кода в десятки раз.
	\item Из-за высоких накладных расходов искажается реальная производительность.
	\item Не поддерживает профилирование потоков.
	\item Поддерживает ручную обработку результатов, что неудобно.
\end{enumerate}

\subsubsection{cProfile}

\textbf{\textit{cProfile}} - современный, рекомендуемый tracing профилировщик, входящий в
стандартную библиотеку Python начиная с версии 2.5. Он выполняет инструментирование аналогично
\textbf{profile}, но написан на языке C в виде расширения (C extensions), что обеспечивает на
порядок более высокую скорость работы.

\subsubsection*{Принцип работы}
\textbf{\textit{cProfile}}, аналогично profile, использует перехват событий вызова/возврата через
API профилирования виртуальной машины Python, реализованное на C. Благодаря низкоуровневой
интеграции накладные расходы существенно снижено

\subsubsection*{Использование}
Запустить профилирование можно тремя способами:

\begin{enumerate}
	\item \textbf{Из командной строки:}
	      \begin{lstlisting}[language=bash]
python -m cProfile [-o output_file] script.py
\end{lstlisting}
	\item \textbf{Внутри скрипта:}
	      \begin{lstlisting}[]
import cProfile
cProfile.run('heavy_func()', 'cprofile_stats.prof')
\end{lstlisting}
	\item \textbf{Контекстный менеджер (Python 3.8+):}
	      \begin{lstlisting}[]
with cProfile.Profile() as profiler:
heavy_func()
profiler.dump_stats('cprofile_context.prof')
\end{lstlisting}
\end{enumerate}

\subsubsection*{Анализ результатов}
Как и для \texttt{profile}, статистика сохраняется в бинарном формате
и обрабатывается модулем \textbf{pstats}:

\begin{lstlisting}[]
import pstats
stats = pstats.Stats('cprofile_stats.prof')
# 
stats.strip_dirs() # remove absolute paths
stats.sort_stats('tottime') # sorting by your own time
stats.print_stats(10) # bring out the 10 most "heavy" functions
\end{lstlisting}

Возможно также получение статистики по вызывающим/вызываемым функциям:

\begin{lstlisting}
stats.print_callers(5)
stats.print_callees(5)
\end{lstlisting}

\subsubsection*{Визуализация}
Бинарные файлы, созданные \textbf{cProfile}, могут быть преобразованы
в графические отчёты с помощью сторонних утилит:

\begin{itemize}
	\item \textbf{snakeviz} — веб-интерфейс для интерактивного исследования
	      (команда \textbf{snakeviz cprofile\_stats.prof});
	\item \textbf{gprof2dot} + Graphviz — создание диаграмм в формате DOT
	      ( \textbf{python -m gprof2dot -f pstats cprofile\_stats.prof | dot -Tpng -o output.png} );
	\item \textbf{pyprof2calltree} — конвертация для просмотра в KCachegrind.
\end{itemize}


\subsubsection*{Сравнение с profile}
\begin{itemize}
	\item \textbf{Скорость:} \textbf{cProfile} работает в 5–20 раз быстрее
	      \textbf{profile} (накладные расходы приблизительно 10–30\% против 200–1000\%).
	\item \textbf{Точность:} за счёт меньшего искажения времени выполнения результаты \texttt{cProfile} ближе к реальности.
	\item \textbf{Функциональность:} оба инструмента предоставляют одинаковый набор данных и API, но \texttt{cProfile} дополнительно поддерживает профилирование многопоточных программ.
	\item \textbf{Статус:} \texttt{cProfile} активно поддерживается и рекомендуется официальной документацией; \texttt{profile} сохраняется для обратной совместимости.
\end{itemize}

\subsubsection*{Недостатки cProfile}
\begin{enumerate}
	\item Всё ещё ощутимое замедление (от 10\% до 50\% в зависимости от программы), что ограничивает применение в промышленной эксплуатации.
	\item Невозможность профилирования асинхронного кода (\texttt{async/await}) без дополнительных ухищрений (для этого существуют специализированные инструменты, например \texttt{yappi}).
	\item Отсутствие встроенных средств для анализа использования памяти.
\end{enumerate}

\subsubsection*{Пример использования cProfile: от запуска до визуализации}
Рассмотрим полный цикл работы с \texttt{cProfile} на примере функции, выполняющей вычисление чисел Фибоначчи рекурсивным и итеративным способами. Это позволит наглядно продемонстрировать сбор статистики, её анализ и построение графического отчёта.

\begin{lstlisting}
def fib_recursive(n):
    if n <= 1:
        return n
    return fib_recursive(n-1) + fib_recursive(n-2)

def fib_iterative(n):
    a, b = 0, 1
    for _ in range(n):
        a, b = b, a + b
    return a

def main():
    fib_recursive(35)
    fib_iterative(100000)

if __name__ == "__main__":
    main()
\end{lstlisting}

\paragraph{1. Запуск профилирования}
Выполним профилирование из командной строки, сохранив результаты в файл \texttt{fib.prof}:

\begin{lstlisting}
python -m cProfile -o fib.prof fib.py
\end{lstlisting}

\paragraph{2. Базовый анализ в консоли с помощью pstats}
Загрузим статистику и выведем 5 самых «тяжёлых» функций по собственному времени (\texttt{tottime}):

\begin{lstlisting}
python -m pstats fib.prof
strip
sort tottime
stats 5
\end{lstlisting}

Результат выполнения этих команд представлен на рис. \ref{fig:pstats_output}.
Как видно из скриншота, рекурсивная функция \texttt{fib\_recursive} вызвана
огромное количество раз  и занимает почти всё время
выполнения, тогда как итеративная функция \texttt{fib\_iterative} выполняется практически мгновенно. Уже на этом этапе очевидно узкое место.

\begin{figure}[hbtp]
	\centering
	\includegraphics[width=0.8\textwidth]{pstats_output.png}
	\caption{вывод pstats: 5 самых тяжёлых функций по tottime}
	\label{fig:pstats_output}
\end{figure}
\newpage

\paragraph{3. Интерактивная визуализация с SnakeViz}
SnakeViz предоставляет браузерный интерфейс для изучения результатов. Установка и запуск:

\begin{lstlisting}
pip install snakeviz
snakeviz fib.prof
\end{lstlisting}

Откроется диаграмма в виде «солнечных лучей» (sunburst) или иерархического списка, где размер каждого сектора пропорционален времени выполнения. На ней сразу заметен огромный вклад \texttt{fib\_recursive} и её рекурсивных вызовов.

\begin{figure}[hbtp]
	\centering
	\includegraphics[width=0.8\textwidth]{cpython_snakeviz.png}
	\caption{snakeviz\_cprofile}
	\label{snakeviz_cprofile}
\end{figure}
\newpage


\paragraph{4. Генерация графа вызовов с gprof2dot}
Для создания диаграммы в формате PNG, отображающей связи между функциями, используем \texttt{gprof2dot} и Graphviz:

\begin{lstlisting}
pip install gprof2dot
python -m gprof2dot -f pstats fib.prof | dot -Tpng -o fib_callgraph.png
\end{lstlisting}

Полученное изображение наглядно показывает, что \texttt{fib\_recursive} вызывает саму себя многократно, тогда как \texttt{fib\_iterative} изолирована и не имеет дочерних вызовов.

\paragraph{5. Интеграция с юнит-тестами}
Профилировщик можно встроить в тесты для контроля регрессий. Например, используя \texttt{unittest}:

\begin{lstlisting}
import cProfile
import unittest

class TestFibonacci(unittest.TestCase):
    def test_performance(self):
        profiler = cProfile.Profile()
        profiler.enable()
        fib_iterative(100000)
        profiler.disable()
        stats = pstats.Stats(profiler)
        stats.sort_stats('cumtime')
        # Checking that the execution time does not exceed the threshold
        self.assertLess(stats.total_tt, 0.01)
\end{lstlisting}

\subsubsection{line\_profiler}
\textbf{\textit{line\_profiler}} — сторонний инструмент для построчного профилирования кода Python.
В отличие от \texttt{cProfile}, который показывает время выполнения функций целиком,
\texttt{line\_profiler} измеряет время, затрачиваемое на каждую отдельную строку
внутри функции. Это позволяет с высокой точностью локализовать «узкие места»
на уровне отдельных операций.

\subsubsection*{Установка}
Устанавливается через \texttt{pip}:
\begin{lstlisting}[language=bash]
pip install line_profiler
\end{lstlisting}
После установки становится доступен исполняемый модуль \texttt{kernprof} и сам профилировщик.

\subsubsection*{Принцип работы}
\texttt{line\_profiler} использует инструментирование исходного кода: он модифицирует
байткод функции, вставляя измерительные зонды перед каждой строкой. При выполнении
функции замеряется время, прошедшее между зондами. Накладные
расходы выше, чем у \texttt{cProfile}, но несравнимо более
детальная информация оправдывает это при тонкой оптимизации.

\subsubsection*{Использование}
Основной способ применения — декорирование целевой функции \texttt{@profile}.
Важно: декоратор автоматически добавляется при запуске через
\texttt{kernprof}, вручную импортировать его не нужно.

\begin{lstlisting}
@profile
def slow_function():
	total = 0
	for i in range(100000):
		total += i ** 2
	return total

if __name__ == "__main__":
	slow_function()
\end{lstlisting}

Запуск профилирования:

\begin{lstlisting}[language=bash]
kernprof -l -v example.py
\end{lstlisting}


Ключ \texttt{-l} включает построчный режим (line\_profiler), \texttt{-v}
выводит результат сразу в консоль. По умолчанию создаётся файл
\texttt{example.py.lprof}, который можно просмотреть позже утилитой
\texttt{python -m line\_profiler example.py.lprof}.


\subsubsection*{Пример вывода}
Результат представляет собой таблицу со следующими столбцами:
\begin{figure}[hbtp]
	\centering
	\includegraphics[width=0.8\textwidth]{line_profiler.png}
	\caption{line\_profiler}
	\label{line_profiler}
\end{figure}
\newpage


\begin{itemize}
	\item \texttt{Line} — номер строки;
	\item \texttt{Hits} — количество выполнений данной строки;
	\item \texttt{Time} — общее время, затраченное на строку (в микросекундах);
	\item \texttt{Per Hit} — среднее время одного выполнения;
	\item \texttt{\% Time} — доля от общего времени функции;
	\item \texttt{Line Contents} — исходный код строки.
\end{itemize}

Видно, что основное время тратится на вычисление квадрата и суммирование внутри цикла.

\subsubsection*{Достоинства}
\begin{itemize}
	\item Высочайшая детализация — информация по каждой строке.
	\item Простота использования — достаточно добавить декоратор.
	\item Интеграция с \texttt{IPython}.
\end{itemize}

\subsubsection*{Недостатки}
\begin{itemize}
	\item Замедление работы функции в разы (иногда на порядок), что ограничивает применение на реальных данных.
	\item Необходимость модифицировать исходный код (добавлять декоратор).
	\item Не работает с асинхронными функциями напрямую.
	\item Отсутствие встроенной визуализации (но результаты можно экспортировать).
\end{itemize}

\texttt{line\_profiler} незаменим, когда нужно понять, какая именно операция внутри большой функции тормозит
выполнение, и все другие методы уже не дают достаточной информации.


\subsection{Статистические профилировщики}
\begin{itemize}
	\item py\_spy - семплирование без остановки процесса
	\item pprofile - гибридный подход (детерминированный и статистический режимы)
\end{itemize}


\subsubsection{py-spy}
\textbf{\textit{py-spy}} — семплирующий (статистический) профилировщик для Python-программ,
написанный на языке Rust. Его ключевая особенность — полная независимость от целевого процесса:
\texttt{py-spy} запускается вне интерпретатора Python и читает память профилируемой
программы напрямую через системные вызовы (\texttt{process\_vm\_readv}
в Linux, \texttt{vm\_read} в macOS, \texttt{ReadProcessMemory} в Windows).
Это позволяет:

\begin{itemize}
	\item Профилировать уже запущенные процессы без их остановки;
	\item Не вносить никаких изменений в исходный код;
	\item Работать с production сервисами без заметного
	      влияния на производительность
	\item Собирать данные даже в тех случаях, когда целевой интерпретатор
	      собран без отладочных символов.
\end{itemize}

\subsubsection*{Установка}
\begin{lstlisting}[language=bash]
pip install py-spy
\end{lstlisting}
Также доступна установка через пакетные менеджеры: \texttt{brew install py-spy}
(macOS), \texttt{yay -S py-spy} (Arch Linux), а для Rust-экосистемы
— \texttt{cargo install py-spy}.

\subsubsection*{Принцип работы}
\texttt{py-spy} читает память процесса и обходит структуры CPython. Достиграется
это засчет того, что py-spy находит глобальный PyInterpreterState, из него — все активные потоки, а затем и цепочки объектов \texttt{PyFrameObject}, формирующих стек вызовов. Поскольку \texttt{py-spy} не выполняется внутри интерпретатора, он не перехватывает события вызова/возврата и не замедляет работу кода. Семплирование происходит с заданной частотой (по умолчанию 100 Гц).

\subsubsection*{Базовые команды}
\texttt{py-spy} предоставляет три основных режима работы:

\begin{enumerate}
	\item \textbf{\texttt{record}} — запись профиля в файл с последующей визуализацией:
	      \begin{lstlisting}[language=bash]
# Attach to a running process
py-spy record -o profile.svg --pid 12345

# Start a new process under profiler
py-spy record -o profile.svg -- python myprogram.py
\end{lstlisting}
	      Поддерживаемые форматы: SVG (интерактивный флеймграф), \texttt{speedscope}, сырые данные.

	\item \textbf{\texttt{top}} — интерактивный просмотр «горячих» функций в
	      реальном времени, аналогичный утилите \texttt{top}:
	      \begin{lstlisting}[language=bash]
py-spy top --pid 12345
\end{lstlisting}

	\item \textbf{\texttt{dump}} — мгновенный снимок стека
	      вызовов всех потоков (полезно при зависаниях):
	      \begin{lstlisting}[language=bash]
py-spy dump --pid 12345
py-spy dump --pid 12345 --locals  # also show local variables
\end{lstlisting}
\end{enumerate}

\subsubsection*{Ключевые возможности}
\begin{itemize}
	\item \textbf{Профилирование нативных расширений} (\texttt{--native}) —
	      отображение имён функций из C/C++/Cython (доступно на Linux x86\_64 и Windows) .
	\item \textbf{Отслеживание дочерних процессов} (\texttt{--subprocesses}) —
	      автоматическое прикрепление к порождённым процессам (например, при
	      использовании \texttt{multiprocessing} или \texttt{gunicorn}).
	\item \textbf{Фильтрация по GIL} (\texttt{--gil}) — учёт только потоков
	      , удерживающих глобальную блокировку интерпретатора.
	\item \textbf{Исключение «спящих» потоков} — \texttt{py-spy} опрашивает
	      состояние потоков через \texttt{/proc/PID/stat} (Linux),
	      \texttt{thread\_basic\_info} (macOS) или анализ системных
	      вызовов (Windows) и не включает в отчёт стеки, заведомо находящиеся
	      в ожидании. Поведение можно изменить флагом \texttt{--idle}.
\end{itemize}

\subsubsection*{Особые требования}
При профилировании существующего процесса \texttt{py-spy} требует прав
на чтение чужой памяти. В macOS это всегда требует \texttt{sudo}, в
Linux — если процесс запущен не самим профилировщиком . В контейнерах
Docker и Kubernetes необходимо добавить capability \texttt{SYS\_PTRACE},
иначе вызовы \texttt{process\_vm\_readv} будут запрещены.

\subsubsection*{Достоинства}
\begin{itemize}
	\item Нулевое вмешательство в код программы;
	\item Крайне низкие накладные расходы (применимо в продакшене);
	\item Работа с уже зависшими процессами (команда \texttt{dump});
	\item Наглядная визуализация (флеймграфы, \texttt{speedscope});
	\item Кроссплатформенность (Linux, macOS, Windows, FreeBSD).
\end{itemize}

\subsubsection*{Недостатки}
\begin{itemize}
	\item Статистическая природа — кратковременные функции могут быть «пропущены»;
	\item Требует повышенных привилегий в ряде сценариев;
	\item Не даёт точного числа вызовов, только долевое распределение времени.
\end{itemize}

\texttt{py-spy} — оптимальный выбор для диагностики замедлений в промышленной
эксплуатации, когда невозможно (или нежелательно) перезапускать приложение и
вносить изменения в код.

\subsubsection{pprofile}
\textbf{\textit{pprofile}} — легковесный, полностью написанный на Python профилировщик
, реализующий \textbf{оба} метода сбора информации: детерминированное (trace)
и статистическое (sample) профилирование. Его главная отличительная черта —
\textit{строчная гранулярность} (line-granularity) в сочетании с автоматическим
отслеживанием всех потоков и возможностью работы без модификации исходного кода.

\subsubsection*{Установка}
\begin{lstlisting}[language=bash]
pip install pprofile
\end{lstlisting}
После установки становится доступен одноимённый исполняемый модуль.

\subsubsection*{Два режима работы}

\textbf{1. Детерминированное профилирование (по умолчанию)}
В этом режиме \texttt{pprofile} перехватывает каждое событие выполнения строки
(line events), используя механизм \texttt{sys.settrace}. Это даёт абсолютно полную
картину: сколько раз выполнилась каждая строка, сколько времени заняла,
какова иерархия вызовов. Расплата — огромные накладные расходы (замедление в 10–100 раз),
что ограничивает применение только короткими тестовыми сценариями.

\begin{lstlisting}[language=bash]
# Running the script under a deterministic profiler
pprofile myscript.py

# Ignore system paths (so as not to clutter the output)
pprofile --exclude-syspath myscript.py

# Launching the module
pprofile -m mymodule -- --arg-for-module
\end{lstlisting}

Вывод представляет собой аннотированный исходный код: перед каждой строкой указывается
количество попаданий (Hits), общее время, время на один вызов и доля в процентах.

\begin{lstlisting}[basicstyle=\tiny\ttfamily]
File: demo/threads.py
File duration: 1.00168s (99.60%)
Line #|      Hits|         Time|Time per hit|      %|Source code
------+----------+-------------+------------+------+-----------
     4|         2|  3.21865e-05| 1.60933e-05|  0.00%|    def func():
     5|         1|      1.00111|     1.00111| 99.54%|    time.sleep(1)
\end{lstlisting}

\textbf{2. Статистическое профилирование} (\texttt{--statistic})
В этом режиме \texttt{pprofile} периодически опрашивает стеки всех
потоков (или только текущего) с заданным интервалом. Накладные
расходы снижаются до приемлемых 1–5\%, что позволяет применять
\texttt{pprofile} к длительно работающим приложениям.

\begin{lstlisting}[language=bash]
# Sampling every 0.01 seconds
pprofile --statistic 0.01 myscript.py

# Current stream only (single), 1 ms period
pprofile --statistic 0.001 --single myscript.py
\end{lstlisting}

Недостаток статистического режима — потеря точности: вместо реального времени
выполнения строки показывают только количество «попаданий» в сэмплы, что
даёт лишь приблизительную картину.

\subsubsection*{Поддержка многопоточности}
В отличие от \texttt{cProfile}, \texttt{pprofile} «из коробки» корректно
отслеживает порождаемые потоки. В детерминированном режиме для этого необходимо
установить флаг \texttt{--threads 1} (или \texttt{threads=True} в API),
в статистическом — все потоки процесса видны автоматически.

\subsubsection*{Визуализация (Callgrind / KCachegrind)}
Одна из сильнейших сторон \texttt{pprofile} — экспорт в формат \texttt{callgrind},
совместимый с KCachegrind и QCachegrind. Это даёт возможность исследовать профиль
в графическом интерфейсе с древовидными диаграммами, поиском «горячих» путей и фильтрацией.

\begin{lstlisting}[language=bash]
pprofile --format callgrind --out cachegrind.out.myprofile myscript.py
# Or short entry (file name starts with cachegrind.out)
pprofile --out cachegrind.out.myprofile myscript.py

# Additionally - package the source code in a zip to display the paths correctly
pprofile --out cachegrind.out.myprofile --zipfile src.zip myscript.py
\end{lstlisting}

\subsubsection*{Программный API}
\texttt{pprofile} можно встраивать непосредственно в код, что полезно для
профилирования отдельных участков:

\begin{lstlisting}
import pprofile

# Deterministic site profile
prof = pprofile.Profile()
with prof():
    # ... the code for profiling ...
prof.print_stats()

# Statistical profile (sampling the current stream)
stat_prof = pprofile.StatisticalProfile()
with stat_prof(period=0.001):
# ... the code for profiling ...
stat_prof.print_stats()
\end{lstlisting}

\subsubsection*{Сравнение с line\_profiler}
Оба инструмента дают построчную информацию, но принципиально различаются:

\begin{itemize}
	\item \texttt{line\_profiler} требует декоратора \texttt{@profile}
	      и запуска через \texttt{kernprof}, фокусируясь только на отмеченных функциях;
	\item \texttt{pprofile} анализирует \textit{весь} код приложения
	      без каких-либо изменений, что удобно для первичного поиска узких
	      мест, но порождает огромные объёмы вывода.
\end{itemize}

\subsubsection*{Достоинства}
\begin{itemize}
	\item Чистый Python — работает там, где нельзя собрать C-расширение;
	\item Два режима профилирования в одном инструменте;
	\item Полная поддержка потоков;
	\item Экспорт в Callgrind для профессионального анализа;
	\item Не требует модификации исходного кода (в отличие от \texttt{line\_profiler}).
\end{itemize}

\subsubsection*{Недостатки}
\begin{itemize}
	\item Детерминированный режим неприменим к реальным задачам
	      из-за колоссального замедления;
	\item Статистический режим даёт лишь приблизительные результаты;
	\item Проект давно не обновлялся (последний релиз — 2016 г.) ;
	\item Меньше возможностей визуализации по сравнению с \texttt{py-spy}
	      (флеймграфы не строятся напрямую).
\end{itemize} \texttt{pprofile} занимает нишу «тяжёлой артиллерии» для всестороннего
исследовательского профилирования в окружениях, где недопустима компиляция
или недоступны современные альтернативы. Однако в новых проектах приоритет
следует отдавать \texttt{py-spy} (продакшен) либо связке
\texttt{cProfile} + \texttt{snakeviz} (разработка).

\subsection{Специализированные решения}

\subsubsection{yappi}
\textbf{\textit{yappi}} (Yet Another Python Profiler) — профилировщик, специализирующийся на многопоточных
и асинхронных приложениях. Он поддерживает как инструментирование (\texttt{tracing}),
так и статистический режим (\texttt{wall time} и \texttt{cpu time}), и отличается
низкими накладными расходами при работе с большим количеством потоков.

\subsubsection*{Установка}
\begin{lstlisting}[language=bash]
pip install yappi
\end{lstlisting}

\subsubsection*{Ключевые особенности}
\begin{itemize}
	\item \textbf{Поддержка потоков} — корректно учитывает время выполнения каждого потока отдельно.
	\item \textbf{Поддержка asyncio} — профилирование корутин и задач (с версии 1.3.0).
	\item \textbf{Два режима таймера}: \texttt{wall-time} (реальное время) и \texttt{cpu-time} (процессорное время).
	\item \textbf{Статистическое профилирование} — возможность переключения в режим \texttt{sampling} для минимизации накладных расходов.
	\item \textbf{Богатый API} — запуск, остановка, сброс статистики, получение отчётов в различных форматах.
\end{itemize}

\subsubsection*{Принцип работы}
В режиме \texttt{tracing} \texttt{yappi} аналогично \texttt{cProfile} перехватывает
вызовы функций, но реализация оптимизирована для работы в многопоточной среде (использует
локальные для потока структуры данных). В режиме \texttt{sampling} профилировщик
периодически опрашивает стеки всех потоков, что даёт минимальную задержку.

\subsubsection*{Использование}
Рассмотрим пример профилирования многопоточной программы.

\begin{lstlisting}
import yappi
import threading
import time

def worker(name):
	for _ in range(5):
		time.sleep(0.1)
		print(f"{name} working")

threads = []
for i in range(3):
t = threading.Thread(target=worker, args=(f"Thread-{i}",))
threads.append(t)

yappi.set_clock_type("wall") # "wall" or "cpu"
yappi.start()
for t in threads:
	t.start()
for t in threads:
	t.join()
yappi.stop()

func_stats = yappi.get_func_stats()
func_stats.sort("ttot", type="cum").print_all()

thread_stats = yappi.get_thread_stats()
thread_stats.print_all()

func_stats.save('yappi_stats.prof', type='pstats')
\end{lstlisting}

\subsubsection*{Пример с asyncio}
Начиная с версии 1.3.0, \texttt{yappi} может профилировать асинхронный код.

\begin{lstlisting}
import yappi
import asyncio

async def fetch_data():
	await asyncio.sleep(0.1)
	return "data"

async def main():
	results = await asyncio.gather(fetch_data(), fetch_data(), fetch_data())

	yappi.set_clock_type("wall")
	yappi.start()
	asyncio.run(main())
	yappi.stop()

	stats = yappi.get_func_stats()
	stats.print_all()
\end{lstlisting}

\subsubsection*{Сравнение с cProfile}
\begin{itemize}
	\item \textbf{Потоки:} \texttt{cProfile} не разделяет статистику по потокам — все вызовы смешиваются;
	      \texttt{yappi} предоставляет отдельную статистику для каждого потока.
	\item \textbf{Asyncio:} \texttt{cProfile} видит только вызовы функций, но не корутины;
	      \texttt{yappi} корректно отображает время выполнения асинхронных задач.
	\item \textbf{Скорость:} В режиме \texttt{tracing} \texttt{yappi} немного медленнее
	      \texttt{cProfile} из-за дополнительных блокировок; в режиме \texttt{sampling} — значительно быстрее.
	\item \textbf{Гибкость:} \texttt{yappi} позволяет динамически переключать режимы,
	      очищать статистику и профилировать только интересующие потоки.
\end{itemize}

\subsubsection*{Достоинства}
\begin{itemize}
	\item Полноценная поддержка многопоточности и asyncio.
	\item Два режима профилирования (инструментирование и семплирование).
	\item Низкие накладные расходы в режиме \texttt{sampling} (подходит для продакшена).
	\item Богатый API и возможность экспорта в формат \texttt{pstats}.
	\item Поддержка профилирования времени ЦП и реального времени.
\end{itemize}

\subsubsection*{Недостатки}
\begin{itemize}
	\item Менее распространён, чем \texttt{cProfile}, меньше интеграций
	      с визуализаторами (хотя файлы \texttt{pstats} совместимы).
	\item В режиме \texttt{tracing} может быть медленнее
	      \texttt{cProfile} для однопоточных приложений.
	\item Документация не всегда подробна, хотя проект
	      активно развивается.
\end{itemize}

\texttt{yappi} становится незаменимым инструментом при разработке
высоконагруженных сетевых сервисов, веб-приложений на asyncio, а также
при необходимости профилирования в условиях, когда нельзя останавливать сервер (режим семплирования).


\section{Профилирование нативных расширений (C extensions)}
\subsection{Особенности профилирование кода на C/C++ внутри Python}
\subsection{Инструменты для анализа C/C++: gprof, Valgrind (Callgrind), Google PerfTools}
\subsection{Получение смешанных стеков вызовов (Python + C) с помощью perf и eBPF}

\section{Системное профилирование Python-приложений}
\subsection{Использование утилиты perf в Linux для анализа на уровне ядра}
\subsection{DTrace и SystemTap: динамическая трассировка}
\subsection{Профилирование операций ввода-вывода и работы с сетью}

\section{Сравнительный анализ и практические рекомендации}

\end{document}
